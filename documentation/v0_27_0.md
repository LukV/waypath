# Waypath Backend Structure (v0.27.0, May 2025)

## 🚀 Overview

Waypath v0.27.0 is a cleanly structured FastAPI application that supports document parsing and structured data extraction through both API and CLI. The core flow is centered around orders extracted from uploaded documents or incoming emails. A modular pipeline coordinates parsing, extraction, persistence, and job tracking.

---

## 🧱 Current Tech Stack

| Technology         | Purpose                       |
| ------------------ | ----------------------------- |
| FastAPI            | Async web API framework       |
| SQLAlchemy 2.0     | Async ORM                     |
| SQLite + aiosqlite | Development database          |
| ULID               | Unique sortable identifiers   |
| LlamaParse / Azure | Document parsing backends     |
| OpenAI / Azure AI  | Markdown-to-schema extraction |
| PydanticAI         | Extractor output enforcement  |
| Typer              | CLI interface                 |
| dotenv             | Load environment variables    |

---

## 📁 Project Structure

```bash
src/
├── api/
│   ├── app.py              # FastAPI app with lifespan setup
│   ├── crud/               # DB access for users, jobs, orders
│   ├── routers/            # All HTTP route definitions
│   └── schemas/            # Pydantic request/response models
├── core/
│   ├── cli.py              # Typer CLI entry point
│   ├── db/                 # SQLAlchemy models
│   ├── logic/              # Pipeline that drives parsing+extraction
│   ├── services/
│   │   ├── extractors/     # OpenAI & Azure extractors
│   │   └── parsers/        # LlamaParse & Azure document parsers
│   ├── utils/              # Common tools (auth, logging, file I/O)
│   └── schemas/            # Shared core schemas (orders, jobs)
```

---

## 🔁 Entry Points

### CLI

* `core/cli.py`
* Parses document on disk using specified parser and extractor
* Shows parsed `Order` output via `rich`

### API

* `/orders/upload` → upload file from frontend
* `/inbound-email` → Mailgun webhook
* `/orders/generate` → extract-only (no DB write)

All endpoints rely on `process_uploaded_order()` and `DocumentPipeline` under the hood.

---

## 🧠 Core Concepts

### Document Pipeline

```python
@dataclass
class DocumentPipeline:
    parser: AbstractDocumentParser
    extractor: AbstractOrderExtractor
    ...
```

* **Input**: Path to document
* **Steps**:

  1. Parse to Markdown
  2. Extract structured `Order`
  3. Optionally track job status

### Parser Registry

```python
PARSER_REGISTRY = {
  "llamaparse": LlamaParseParser,
  "azure": AzureDocumentParser,
}
```

### Extractor Registry

```python
EXTRACTOR_REGISTRY = {
  "openai": PydanticOpenAIExtractor,
  "azure": PydanticAzureExtractor,
}
```

---

## 🧩 Adding a New Domain: Invoices

You can replicate the pattern used for `Order`:

1. **Model** (`core/db/models.py`)

   * Add `Invoice`, `InvoiceLine`

2. **Schema** (`core/schemas/invoice.py`)

   * Add `InvoiceCreate`, `InvoiceUpdate`, `InvoiceResponse`

3. **CRUD** (`api/crud/invoices.py`)

   * Add functions to create, read, update, delete invoices

4. **Router** (`api/routers/invoices.py`)

   * Expose endpoints for `/invoices/`

5. **Extractor** (`core/services/extractors/invoice_openai.py`)

   * Add `AbstractInvoiceExtractor`
   * Extend `DocumentPipeline` to support invoices

6. **CLI Support**

   * Extend CLI to support parsing/extracting invoices

7. **Factory Registration**

   * Register the new extractor in `EXTRACTOR_REGISTRY`

---

## 🔒 Authentication

* JWT Bearer tokens
* Handled via `core/utils/auth.py`
* Integrated into all `Depends(get_current_user)` calls

---

## 📬 Inbound Email

* `/inbound-email` endpoint processes emails via Mailgun webhook
* Verifies signature, extracts attachments
* Saves files, invokes `process_uploaded_order()`
* Cleans up afterward

---

## 🛠️ Utility Modules

* `utils/logging.py` → Logging setup
* `utils/database.py` → Async DB session creation
* `utils/idsvc.py` → ULID ID generator
